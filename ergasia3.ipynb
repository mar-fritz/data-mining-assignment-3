{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Εργασία 3 (Τεχνικές Εξόρυξης Δεδομένων)\n",
    "## Data Mining: Assignment 3\n",
    "***\n",
    "### Μαρία Φριτζελά 1115201400218\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unicodedata import normalize\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import  svm, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Collection and cleaning of data (Pre-processing text)\n",
    "Date information is not needed so it is not added to our dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "traindf = pd.read_csv(\"data/train.csv\", usecols=['Insult', 'Comment'])\n",
    "testdf = pd.read_csv(\"data/impermium_verification_labels.csv\", index_col='id', usecols=['id', 'Insult', 'Comment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at traindf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>1</td>\n",
       "      <td>\"you are both morons and that is never happening\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Many toolbars include spell check, like Yahoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>\"How about Felix? He is sure turning into one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>\"You're all upset, defending this hipster band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3947 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult                                            Comment\n",
       "0          1                               \"You fuck your dad.\"\n",
       "1          0  \"i really don't understand your point.\\xa0 It ...\n",
       "2          0  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3          0  \"listen if you dont wanna get married to a man...\n",
       "4          0  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...\n",
       "...      ...                                                ...\n",
       "3942       1  \"you are both morons and that is never happening\"\n",
       "3943       0  \"Many toolbars include spell check, like Yahoo...\n",
       "3944       0  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...\n",
       "3945       0  \"How about Felix? He is sure turning into one ...\n",
       "3946       0  \"You're all upset, defending this hipster band...\n",
       "\n",
       "[3947 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the train and test data to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = traindf.Comment, traindf.Insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = testdf.Comment, testdf.Insult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up train comments' text:\n",
    "- convert all letters to lowercase\n",
    "- remove multiple instances of '\\'<br>\n",
    "For example \"\\\\\\n\" becomes \"\\n\"\n",
    "- remove \"\\n\" and \"\\xa0\" (non-breaking space latin)\n",
    "- remove usernames\n",
    "- remove URLs\n",
    "- remove special unicode characters (like \\xe1, \\xe2...)<br>\n",
    "- remove puctuation\n",
    "- remove all words containing digits, and any digits\n",
    "- remove multiple spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(comments):\n",
    "    return comments.apply(lambda comment: comment.lower())\\\n",
    "                .apply(lambda comment: re.sub(\"\\\\\\\\*\\\\\\\\\", \" \\\\\\\\\" ,comment))\\\n",
    "                .apply(lambda comment: re.sub(\"\\\\\\\\+n|\\\\\\\\+xa0\", \" \", comment))\\\n",
    "                .apply(lambda comment: re.sub('@[^\\s]+',' ',comment))\\\n",
    "                .apply(lambda comment: re.sub('(http(s)?:\\/\\/|www\\.)(\\S|[a-z]|[A-Z]| [0-9])+', \" \", comment))\\\n",
    "                .apply(lambda comment: re.sub('\\\\\\\\+\\S+',\" \", comment))\\\n",
    "                .apply(lambda comment: re.sub('[^A-Za-z0-9 ]+', ' ',comment))\\\n",
    "                .apply(lambda comment: re.sub(r'\\w*\\d\\w*', '', comment))\\\n",
    "                .apply(lambda comment: re.sub(r\"\\s+\",\" \", comment, flags = re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_comments(traindf.Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = clean_comments(testdf.Comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example this comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Nope. Not working for me either.32-23-34www.facebook.com/annagillmodel\\\\\\\\n\\\\\\\\n \\\\\\\\n\\\\\\\\nYou have my email! :) \"'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.Comment[124]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has been transformed into this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' nope not working for me either you have my email '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[124]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our cleaned up data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      you fuck your dad \n",
       "1        i really don t understand your point it seems...\n",
       "2        a majority of canadians can and has been wron...\n",
       "3        listen if you dont wanna get married to a man...\n",
       "4        c b xu bi t c ho kh c ng d ng cu chi nh c ho ...\n",
       "                              ...                        \n",
       "3942     you are both morons and that is never happening \n",
       "3943     many toolbars include spell check like yahoo ...\n",
       "3944     sioux falls s d i told my boy he should call ...\n",
       "3945     how about felix he is sure turning into one h...\n",
       "3946     you re all upset defending this hipster band ...\n",
       "Name: Comment, Length: 3947, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Naive Bayes\n",
    "\n",
    "Transform the comments into word count vectors using CountVectorizer from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bag-of-words vector\n",
    "bow_vectorizer = CountVectorizer(max_features=4000)\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the vector of the first comment in the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dad</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plutocrats</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finals</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financial</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finding</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            counts\n",
       "you              1\n",
       "your             1\n",
       "dad              1\n",
       "fuck             1\n",
       "plutocrats       0\n",
       "...            ...\n",
       "finals           0\n",
       "financial        0\n",
       "find             0\n",
       "finding          0\n",
       "zoo              0\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_bow[0:1].T.todense(), index=bow_vectorizer.get_feature_names(), columns=[\"counts\"])\\\n",
    ".sort_values(by=[\"counts\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model on the BoW training set\n",
    "nb.fit(X_train_bow.toarray(), y_train)\n",
    "# predict the BoW test set\n",
    "y_pred_nb_bow = nb.predict(X_test_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation Precision NB for BoW: 0.5840240145124168\n",
      "10-fold Cross Validation Recall NB for BoW: 0.6038477436535545\n",
      "10-fold Cross Validation F-Measure NB for BoW: 0.578019561577787\n",
      "10-fold Cross Validation Accuracy NB for BoW: 0.6214971406541155\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation Precision NB for BoW:\",\n",
    "      np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train, cv=10, scoring='precision_macro')))\n",
    "print(\"10-fold Cross Validation Recall NB for BoW:\",\n",
    "      np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train, cv=10, scoring='recall_macro')))\n",
    "print(\"10-fold Cross Validation F-Measure NB for BoW:\",\n",
    "     np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy NB for BoW:\",\n",
    "      np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision NB for BoW: [0.54244032 0.49426063]\n",
      "Recall NB for BoW: [0.35319516 0.67966574]\n",
      "F-Measure NB for BoW: [0.42782427 0.57232213]\n",
      "\n",
      "Accuracy NB for BoW: 0.5105145413870246\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision NB for BoW:\",metrics.precision_score(y_test, y_pred_nb_bow, average=None))\n",
    "print(\"Recall NB for BoW:\",metrics.recall_score(y_test, y_pred_nb_bow, average=None))\n",
    "print(\"F-Measure NB for BoW:\", metrics.f1_score(y_test, y_pred_nb_bow, average=None))\n",
    "print()\n",
    "print(\"Accuracy NB for BoW:\",metrics.accuracy_score(y_test,y_pred_nb_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scores are not very good... Let's improve them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the scores of Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use lemmatization of words to improve the scores from the previous question, using the WordNetLemmatizer from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "X_train_lem = X_train.apply(lambda item: ' '.join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(item)]))\n",
    "X_test_lem = X_test.apply(lambda item: ' '.join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(item)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bag-of-words vector\n",
    "bow_vectorizer = CountVectorizer(max_features=4000)\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train_lem)\n",
    "X_test_bow = bow_vectorizer.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the lemmatized BoW training set\n",
    "nb.fit(X_train_bow.toarray(), y_train)\n",
    "# predict the BoW test set\n",
    "y_pred_nb_bow = nb.predict(X_test_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure NB for Lemmatized BoW data: [0.42752868 0.56974922]\n",
      "\n",
      "Accuracy NB for Lemmatized BoW data: 0.508724832214765\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure NB for Lemmatized BoW data:\", metrics.f1_score(y_test, y_pred_nb_bow, average=None))\n",
    "print()\n",
    "print(\"Accuracy NB for Lemmatized BoW data:\",metrics.accuracy_score(y_test,y_pred_nb_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Stop word filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a bag-of-words vector, removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bag-of-words vector\n",
    "bow_vectorizer = CountVectorizer(max_features=4000, stop_words='english')\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the stopword free BoW training set\n",
    "nb.fit(X_train_bow.toarray(), y_train)\n",
    "# predict the BoW test set\n",
    "y_pred_nb_bow = nb.predict(X_test_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure NB for stopword free BoW data: [0.42010582 0.5751938 ]\n",
      "\n",
      "Accuracy NB for stopword free BoW data: 0.5096196868008949\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure NB for stopword free BoW data:\", metrics.f1_score(y_test, y_pred_nb_bow, average=None))\n",
    "print()\n",
    "print(\"Accuracy NB for stopword free BoW data:\",metrics.accuracy_score(y_test,y_pred_nb_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Use of bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a bag-of-words vector, including bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bag-of-words vector\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(1,2), max_features=4000)\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the lemmatized BoW training set\n",
    "nb.fit(X_train_bow.toarray(), y_train)\n",
    "# predict the BoW test set\n",
    "y_pred_nb_bow = nb.predict(X_test_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure NB for Lemmatized BoW data: [0.39311494 0.59048333]\n",
      "\n",
      "Accuracy NB for Lemmatized BoW data: 0.5109619686800895\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure NB for Lemmatized BoW data:\", metrics.f1_score(y_test, y_pred_nb_bow, average=None))\n",
    "print()\n",
    "print(\"Accuracy NB for Lemmatized BoW data:\",metrics.accuracy_score(y_test,y_pred_nb_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bag-of-words vector\n",
    "bow_vectorizer = CountVectorizer(max_features=4000)\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a=1 is called Laplace smoothing\n",
    "\n",
    "_(https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "mnb = MultinomialNB(alpha=1.0)\n",
    "\n",
    "# Train the model on the BoW training set\n",
    "mnb.fit(X_train_bow.toarray(), y_train)\n",
    "# predict the BoW test set\n",
    "y_pred_mnb_bow = mnb.predict(X_test_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure NB for BoW: [0.62959381 0.68109908]\n",
      "\n",
      "Accuracy NB for BoW: 0.6572706935123043\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure NB for BoW:\", metrics.f1_score(y_test, y_pred_mnb_bow, average=None))\n",
    "print()\n",
    "print(\"Accuracy NB for BoW:\",metrics.accuracy_score(y_test,y_pred_mnb_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bag-of-words vector\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(1,2), max_features=4000, stop_words='english')\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train_lem)\n",
    "X_test_bow = bow_vectorizer.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the BoW training set\n",
    "mnb.fit(X_train_bow.toarray(), y_train)\n",
    "# predict the BoW test set\n",
    "y_pred_mnb_bow = mnb.predict(X_test_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation Precision NB for BoW: 0.7413755088411647\n",
      "10-fold Cross Validation Recall NB for BoW: 0.7663864912480829\n",
      "10-fold Cross Validation F-Measure NB for BoW: 0.7507234216792603\n",
      "10-fold Cross Validation Accuracy NB for BoW: 0.7945229068945576\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation Precision NB for BoW:\",\n",
    "      np.mean(cross_val_score(mnb, X_train_bow.toarray(), y_train, cv=10, scoring='precision_macro')))\n",
    "print(\"10-fold Cross Validation Recall NB for BoW:\",\n",
    "      np.mean(cross_val_score(mnb, X_train_bow.toarray(), y_train, cv=10, scoring='recall_macro')))\n",
    "print(\"10-fold Cross Validation F-Measure NB for BoW:\",\n",
    "     np.mean(cross_val_score(mnb, X_train_bow.toarray(), y_train, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy NB for BoW:\",\n",
    "      np.mean(cross_val_score(mnb, X_train_bow.toarray(), y_train, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision NB for BoW: [0.68045113 0.72044199]\n",
      "Recall NB for BoW: [0.78151986 0.60538533]\n",
      "F-Measure NB for BoW: [0.72749196 0.65792129]\n",
      "\n",
      "Accuracy NB for BoW: 0.6966442953020134\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision NB for BoW:\",metrics.precision_score(y_test, y_pred_mnb_bow, average=None))\n",
    "print(\"Recall NB for BoW:\",metrics.recall_score(y_test, y_pred_mnb_bow, average=None))\n",
    "print(\"F-Measure NB for BoW:\", metrics.f1_score(y_test, y_pred_mnb_bow, average=None))\n",
    "print()\n",
    "print(\"Accuracy NB for BoW:\",metrics.accuracy_score(y_test,y_pred_mnb_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! **~20%** improvement in scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of a custom feature vector: TF/IDF Vector & Part-of-Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-Speech frequency features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use nltk's pos_tag method for each word of every comment in our data. Set the tagset attribute to 'universal' in the pos_tag method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tagged = X_train.apply(lambda item: nltk.pos_tag(nltk.word_tokenize(item), tagset='universal'))\n",
    "X_test_tagged = X_test.apply(lambda item: nltk.pos_tag(nltk.word_tokenize(item), tagset='universal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the result looks like for comment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'NOUN'),\n",
       " ('really', 'ADV'),\n",
       " ('don', 'ADJ'),\n",
       " ('t', 'NOUN'),\n",
       " ('understand', 'VERB'),\n",
       " ('your', 'PRON'),\n",
       " ('point', 'NOUN'),\n",
       " ('it', 'PRON'),\n",
       " ('seems', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('you', 'PRON'),\n",
       " ('are', 'VERB'),\n",
       " ('mixing', 'VERB'),\n",
       " ('apples', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('oranges', 'NOUN')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tagged[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency distribution (`nltk.FreqDist`) can be defined as a function mapping from each sample to the number of times that sample occurred as an outcome.<br>\n",
    "It will be used to record the frequency of each word type in each comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NOUN': 5, 'VERB': 4, 'PRON': 3, 'ADV': 1, 'ADJ': 1, 'ADP': 1, 'CONJ': 1})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(tag for word, tag in X_train_tagged[1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function fractPOS:** Creates a list of dictionaries iterating through every comment passed in X_tagged. Each dictionary holds the fraction (=frequency_of_tag/number_of_words_in_comment) of each tag for that comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractPOS(X_tagged):\n",
    "    fractions = []\n",
    "    for tagged_comment in X_tagged:\n",
    "        n_of_words = len(tagged_comment)\n",
    "        freq = nltk.FreqDist(tag for word, tag in tagged_comment)\n",
    "        # freq[tag_type] if a tag type doesn't exist, zero is returned\n",
    "        try:\n",
    "            d = {\n",
    "                'ADV': freq['ADV']/n_of_words,\n",
    "                'VERB': freq['VERB']/n_of_words,\n",
    "                'ADJ': freq['ADJ']/n_of_words,\n",
    "                'NOUN': freq['NOUN']/n_of_words\n",
    "            }\n",
    "        except ZeroDivisionError: #n_of_words ==0\n",
    "            d = {'ADV': 0, 'VERB': 0, 'ADJ': 0,'NOUN': 0}\n",
    "        fractions.append(d)\n",
    "    return fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe is created using the list of dictionaries.<br>\n",
    "_We chose not to fill the dataframe row by row, because iteratively appending rows to a DataFrame can be computationally intensive_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['ADV', 'VERB', 'ADJ', 'NOUN']\n",
    "X_train_freqdf = pd.DataFrame(fractPOS(X_train_tagged), columns=tags)\n",
    "X_test_freqdf = pd.DataFrame(fractPOS(X_test_tagged), columns=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our custom feature vector (dataframe) for the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.202899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.118644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.244444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3947 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADV      VERB       ADJ      NOUN\n",
       "0     0.000000  0.250000  0.000000  0.250000\n",
       "1     0.062500  0.250000  0.062500  0.312500\n",
       "2     0.086957  0.202899  0.057971  0.202899\n",
       "3     0.033898  0.305085  0.084746  0.118644\n",
       "4     0.000000  0.047619  0.063492  0.809524\n",
       "...        ...       ...       ...       ...\n",
       "3942  0.111111  0.333333  0.000000  0.111111\n",
       "3943  0.076923  0.346154  0.076923  0.153846\n",
       "3944  0.000000  0.307692  0.076923  0.269231\n",
       "3945  0.111111  0.222222  0.027778  0.277778\n",
       "3946  0.022222  0.222222  0.044444  0.244444\n",
       "\n",
       "[3947 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_freqdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF/IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a TF/IDF vector inluding bigrams and filtering out stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer= TfidfVectorizer(ngram_range=(1,2), max_features=4000, stop_words='english')\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dad</th>\n",
       "      <td>0.855421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>0.517933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pets</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philosophies</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food stamps</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fooled</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tfidf\n",
       "dad           0.855421\n",
       "fuck          0.517933\n",
       "pets          0.000000\n",
       "ph            0.000000\n",
       "philosophies  0.000000\n",
       "...                ...\n",
       "food          0.000000\n",
       "food stamps   0.000000\n",
       "fool          0.000000\n",
       "fooled        0.000000\n",
       "zoo           0.000000\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_tfidf[0:1].T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\\\n",
    ".sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the custom part-of-speech features with the TF/IDF vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF vector is a matrix where the rows are comments and the columns are features.<br>\n",
    "To combine all features, the custom features will be added as columns to the end of the TF/IDF matrix.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF/IDF matrix is a sparse matrix (from Scipy).<br>\n",
    "To save memory, do not convert to dense, rather use `scipy.sparse.hstack` to stack the matrices horizontally (column wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_freqdf])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_freqdf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined matrix consists of 3947 rows (same as the number of comments in the train dataset) and 4000 features from TFIDF + 4 custom part-of-speech features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3947, 4004)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "_(https://stackoverflow.com/questions/48573174/how-to-combine-tfidf-features-with-other-features)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the assigment details, scoring should be calculated calculated using: classification accuracy and F1 score.\n",
    "\n",
    "Find optimal parameters for the SVM model as shown in this example:<br>\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1_macro\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['f1_macro', 'accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        svm.SVC(), tuned_parameters, scoring=score\n",
    "    )\n",
    "    clf.fit(X_train_combined, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the model\n",
    "svm_clf = svm.SVC(C=1, kernel='linear')\n",
    "\n",
    "# train the model on the custom training set\n",
    "svm_clf.fit(X_train_combined, y_train)\n",
    "# predict the custom test set\n",
    "y_pred_svm = svm_clf.predict(X_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation F-Measure SVM for custom feature vector: 0.7716475529688832\n",
      "10-fold Cross Validation Accuracy SVM for custom feature vector: 0.8386172331812635\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation F-Measure SVM for custom feature vector:\",\n",
    "     np.mean(cross_val_score(svm_clf, X_train_combined, y_train, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy SVM for custom feature vector:\",\n",
    "      np.mean(cross_val_score(svm_clf, X_train_combined, y_train, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure SVM for custom feature vector: [0.75342948 0.56914567]\n",
      "Accuracy SVM for custom feature vector: 0.6863534675615213\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure SVM for custom feature vector:\", metrics.f1_score(y_test, y_pred_svm, average=None))\n",
    "print(\"Accuracy SVM for custom feature vector:\",metrics.accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Train the model on the custom training set\n",
    "rf.fit(X_train_combined, y_train)\n",
    "# predict the custom test set\n",
    "y_pred_rf = rf.predict(X_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation F-Measure RF for custom feature vector: 0.7289609591596767\n",
      "10-fold Cross Validation Accuracy RF for custom feature vector: 0.8208719398573538\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation F-Measure RF for custom feature vector:\",\n",
    "     np.mean(cross_val_score(rf, X_train_combined, y_train, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy RF for custom feature vector:\",\n",
    "      np.mean(cross_val_score(rf, X_train_combined, y_train, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure RF for custom feature vector: [0.74498963 0.53172589]\n",
      "Accuracy RF for custom feature vector: 0.6697986577181209\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure RF for custom feature vector:\", metrics.f1_score(y_test, y_pred_rf, average=None))\n",
    "print(\"Accuracy RF for custom feature vector:\",metrics.accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the custom training set\n",
    "mnb.fit(X_train_combined.toarray(), y_train)\n",
    "# predict the custom test set\n",
    "y_pred_mnb_bow = mnb.predict(X_test_combined.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure NB for custom feature vector: [0.71946986 0.31667948]\n",
      "\n",
      "Accuracy NB for custom feature vector: 0.6022371364653244\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure NB for custom feature vector:\", metrics.f1_score(y_test, y_pred_mnb_bow, average=None))\n",
    "print()\n",
    "print(\"Accuracy NB for custom feature vector:\",metrics.accuracy_score(y_test,y_pred_mnb_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
