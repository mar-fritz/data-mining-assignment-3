{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Εργασία 2 (Τεχνικές Εξόρυξης Δεδομένων)\n",
    "## Data Mining: Assignment 2\n",
    "***\n",
    "### Μαρία Φριτζελά 1115201400218\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unicodedata import normalize\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import  svm, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Collection and cleaning of data\n",
    "Date information is not needed so it is not added to our dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "traindf = pd.read_csv(\"data/train.csv\", usecols=['Insult', 'Comment'])\n",
    "testdf = pd.read_csv(\"data/impermium_verification_labels.csv\", index_col='id', usecols=['id', 'Insult', 'Comment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at traindf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>1</td>\n",
       "      <td>\"you are both morons and that is never happening\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Many toolbars include spell check, like Yahoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>\"How about Felix? He is sure turning into one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>\"You're all upset, defending this hipster band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3947 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult                                            Comment\n",
       "0          1                               \"You fuck your dad.\"\n",
       "1          0  \"i really don't understand your point.\\xa0 It ...\n",
       "2          0  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3          0  \"listen if you dont wanna get married to a man...\n",
       "4          0  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...\n",
       "...      ...                                                ...\n",
       "3942       1  \"you are both morons and that is never happening\"\n",
       "3943       0  \"Many toolbars include spell check, like Yahoo...\n",
       "3944       0  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...\n",
       "3945       0  \"How about Felix? He is sure turning into one ...\n",
       "3946       0  \"You're all upset, defending this hipster band...\n",
       "\n",
       "[3947 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the train and test data to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = traindf.Comment, traindf.Insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = testdf.Comment, testdf.Insult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up train comments' text:\n",
    "- convert all letters to lowercase\n",
    "- remove multiple instances of '\\'<br>\n",
    "For example \"\\\\\\n\" becomes \"\\n\"\n",
    "- remove \"\\n\" and \"\\xa0\" (non-breaking space latin)\n",
    "- remove usernames\n",
    "- remove URLs\n",
    "- remove special unicode characters (like \\xe1, \\xe2...)<br>\n",
    "- remove puctuation\n",
    "- remove all words containing digits, and any digits\n",
    "- remove multiple spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(comments):\n",
    "    return comments.apply(lambda comment: comment.lower())\\\n",
    "                .apply(lambda comment: re.sub(\"\\\\\\\\*\\\\\\\\\", \" \\\\\\\\\" ,comment))\\\n",
    "                .apply(lambda comment: re.sub(\"\\\\\\\\+n|\\\\\\\\+xa0\", \" \", comment))\\\n",
    "                .apply(lambda comment: re.sub('@[^\\s]+',' ',comment))\\\n",
    "                .apply(lambda comment: re.sub('(http(s)?:\\/\\/|www\\.)(\\S|[a-z]|[A-Z]| [0-9])+', \" \", comment))\\\n",
    "                .apply(lambda comment: re.sub('\\\\\\\\+\\S+',\" \", comment))\\\n",
    "                .apply(lambda comment: re.sub('[^A-Za-z0-9 ]+', ' ',comment))\\\n",
    "                .apply(lambda comment: re.sub(r'\\w*\\d\\w*', '', comment))\\\n",
    "                .apply(lambda comment: re.sub(r\"\\s+\",\" \", comment, flags = re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_comments(traindf.Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = clean_comments(testdf.Comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example this comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Nope. Not working for me either.32-23-34www.facebook.com/annagillmodel\\\\\\\\n\\\\\\\\n \\\\\\\\n\\\\\\\\nYou have my email! :) \"'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.Comment[124]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has been transformed into this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' nope not working for me either you have my email '"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[124]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our cleaned up data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      you fuck your dad \n",
       "1        i really don t understand your point it seems...\n",
       "2        a majority of canadians can and has been wron...\n",
       "3        listen if you dont wanna get married to a man...\n",
       "4        c b xu bi t c ho kh c ng d ng cu chi nh c ho ...\n",
       "                              ...                        \n",
       "3942     you are both morons and that is never happening \n",
       "3943     many toolbars include spell check like yahoo ...\n",
       "3944     sioux falls s d i told my boy he should call ...\n",
       "3945     how about felix he is sure turning into one h...\n",
       "3946     you re all upset defending this hipster band ...\n",
       "Name: Comment, Length: 3947, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Naive Bayes\n",
    "\n",
    "Transform the comments into word count vectors using CountVectorizer from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bag-of-words vector\n",
    "bow_vectorizer = CountVectorizer(max_features=4000)\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the vector of the first comment in the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dad</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pointing</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filthy</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finally</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finance</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          counts\n",
       "you            1\n",
       "dad            1\n",
       "fuck           1\n",
       "your           1\n",
       "pointing       0\n",
       "...          ...\n",
       "filthy         0\n",
       "final          0\n",
       "finally        0\n",
       "finance        0\n",
       "zoo            0\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_bow[0:1].T.todense(), index=bow_vectorizer.get_feature_names(), columns=[\"counts\"])\\\n",
    ".sort_values(by=[\"counts\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model on the BoW training set\n",
    "nb.fit(X_train_bow.toarray(), y_train)\n",
    "# predict the BoW test set\n",
    "y_pred_nb_bow = nb.predict(X_test_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation Precision NB for BoW: 0.5840240145124168\n",
      "10-fold Cross Validation Recall NB for BoW: 0.6038477436535545\n",
      "10-fold Cross Validation F-Measure NB for BoW: 0.578019561577787\n",
      "10-fold Cross Validation Accuracy NB for BoW: 0.6214971406541155\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation Precision NB for BoW:\",\n",
    "      np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train, cv=10, scoring='precision_macro')))\n",
    "print(\"10-fold Cross Validation Recall NB for BoW:\",\n",
    "      np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train, cv=10, scoring='recall_macro')))\n",
    "print(\"10-fold Cross Validation F-Measure NB for BoW:\",\n",
    "     np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy NB for BoW:\",\n",
    "      np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision NB for BoW: [0.54244032 0.49426063]\n",
      "Recall NB for BoW: [0.35319516 0.67966574]\n",
      "F-Measure NB for BoW: [0.42782427 0.57232213]\n",
      "\n",
      "Accuracy NB for BoW: 0.5105145413870246\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision NB for BoW:\",metrics.precision_score(y_test, y_pred_nb_bow, average=None))\n",
    "print(\"Recall NB for BoW:\",metrics.recall_score(y_test, y_pred_nb_bow, average=None))\n",
    "print(\"F-Measure NB for BoW:\", metrics.f1_score(y_test, y_pred_nb_bow, average=None))\n",
    "print()\n",
    "print(\"Accuracy NB for BoW:\",metrics.accuracy_score(y_test,y_pred_nb_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scores are not very good... Let's improve them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the scores of Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use lemmatization of words to improve the scores from the previous question, using the WordNetLemmatizer from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "X_train = X_train.apply(lambda item: ' '.join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(item)]))\n",
    "X_test = X_test.apply(lambda item: ' '.join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(item)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Use of bigrams and Stop word filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new improved bag-of-words vector, including bigrams and filtering out stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bag-of-words vector\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(1,2), max_features=4000, stop_words='english')\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Laplace Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a=1 is called Laplace smoothing\n",
    "\n",
    "_(https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "mnb = MultinomialNB(alpha=1.0)\n",
    "\n",
    "# Train the model on the BoW training set\n",
    "mnb.fit(X_train_bow.toarray(), y_train)\n",
    "# predict the BoW test set\n",
    "y_pred_mnb_bow = mnb.predict(X_test_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation Precision NB for BoW: 0.7392375343304849\n",
      "10-fold Cross Validation Recall NB for BoW: 0.7639656811390495\n",
      "10-fold Cross Validation F-Measure NB for BoW: 0.7485289705475866\n",
      "10-fold Cross Validation Accuracy NB for BoW: 0.7927533251943713\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation Precision NB for BoW:\",\n",
    "      np.mean(cross_val_score(mnb, X_train_bow.toarray(), y_train, cv=10, scoring='precision_macro')))\n",
    "print(\"10-fold Cross Validation Recall NB for BoW:\",\n",
    "      np.mean(cross_val_score(mnb, X_train_bow.toarray(), y_train, cv=10, scoring='recall_macro')))\n",
    "print(\"10-fold Cross Validation F-Measure NB for BoW:\",\n",
    "     np.mean(cross_val_score(mnb, X_train_bow.toarray(), y_train, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy NB for BoW:\",\n",
    "      np.mean(cross_val_score(mnb, X_train_bow.toarray(), y_train, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision NB for BoW: [0.68045113 0.72044199]\n",
      "Recall NB for BoW: [0.78151986 0.60538533]\n",
      "F-Measure NB for BoW: [0.72749196 0.65792129]\n",
      "\n",
      "Accuracy NB for BoW: 0.6966442953020134\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision NB for BoW:\",metrics.precision_score(y_test, y_pred_mnb_bow, average=None))\n",
    "print(\"Recall NB for BoW:\",metrics.recall_score(y_test, y_pred_mnb_bow, average=None))\n",
    "print(\"F-Measure NB for BoW:\", metrics.f1_score(y_test, y_pred_mnb_bow, average=None))\n",
    "print()\n",
    "print(\"Accuracy NB for BoW:\",metrics.accuracy_score(y_test,y_pred_mnb_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! **~20%** improvement in scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF/IDF Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a TF/IDF vector inluding bigrams and filtering out stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer= TfidfVectorizer(ngram_range=(1,2), max_features=4000, stop_words='english')\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dad</th>\n",
       "      <td>0.853429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>0.521210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plain</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pill</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pin</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forever</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forget</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgive</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tfidf\n",
       "dad      0.853429\n",
       "fuck     0.521210\n",
       "plain    0.000000\n",
       "pill     0.000000\n",
       "pin      0.000000\n",
       "...           ...\n",
       "forest   0.000000\n",
       "forever  0.000000\n",
       "forget   0.000000\n",
       "forgive  0.000000\n",
       "zoo      0.000000\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_tfidf[0:1].T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\\\n",
    ".sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the assigment details, scoring should be calculated calculated using: classification accuracy and F1 score.\n",
    "\n",
    "Find optimal parameters for the SVM model as shown in this example:<br>\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1_macro\n",
      "Best parameters set found on development set:\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['f1_macro', 'accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        svm.SVC(), tuned_parameters, scoring=score\n",
    "    )\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the model\n",
    "svm_clf = svm.SVC(C=1, kernel='linear')\n",
    "\n",
    "# train the model on the TF/IDF training set\n",
    "svm_clf.fit(X_train_tfidf, y_train)\n",
    "# predict the TF/IDF test set\n",
    "y_pred_svm_tfidf = svm_clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation F-Measure SVM for TF/IDF: 0.7611806053010486\n",
      "10-fold Cross Validation Accuracy SVM for TF/IDF: 0.835817001863394\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation F-Measure SVM for TF/IDF:\",\n",
    "     np.mean(cross_val_score(svm_clf, X_train_tfidf, y_train, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy SVM for TF/IDF:\",\n",
    "      np.mean(cross_val_score(svm_clf, X_train_tfidf, y_train, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure SVM for TF/IDF: [0.74788732 0.5607362 ]\n",
      "Accuracy SVM for TF/IDF: 0.6796420581655481\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure SVM for TF/IDF:\", metrics.f1_score(y_test, y_pred_svm_tfidf, average=None))\n",
    "print(\"Accuracy SVM for TF/IDF:\",metrics.accuracy_score(y_test, y_pred_svm_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Train the model on the TF/IDF training set\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "# predict the TF/IDF test set\n",
    "y_pred_rf_tfidf = rf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation F-Measure RF for TF/IDF: 0.7424000777194075\n",
      "10-fold Cross Validation Accuracy RF for TF/IDF: 0.8244181713037332\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation F-Measure RF for TF/IDF:\",\n",
    "     np.mean(cross_val_score(rf, X_train_tfidf, y_train, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy RF for TF/IDF:\",\n",
    "      np.mean(cross_val_score(rf, X_train_tfidf, y_train, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure RF for TF/IDF: [0.74796172 0.56882959]\n",
      "Accuracy RF for TF/IDF: 0.6818791946308724\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure RF for TF/IDF:\", metrics.f1_score(y_test, y_pred_rf_tfidf, average=None))\n",
    "print(\"Accuracy RF for TF/IDF:\",metrics.accuracy_score(y_test, y_pred_rf_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
